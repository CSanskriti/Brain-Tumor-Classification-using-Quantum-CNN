# -*- coding: utf-8 -*-
"""QCNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u9811GEbj_EhswD_s1SEPsAqBLjCzenm

# Brain Cancer Classification With a Hybrid Quantum-Classical Model <ðŸ§ |1>

## ðŸ‘‰ Objectives
Classifying different Brain Cancer Types based on MRI images using a Hybrid Quantum-Classical Model then Comprare the results with a Classical Model (DenseNet121)

## ðŸ‘‰ Importing needed libraries
"""

# QML
import pennylane as qml

# CML
import tensorflow as tf
from tensorflow import keras as K

# Timer
from timeit import default_timer as timer
from datetime import timedelta

# for data
import pandas as pd
from os import listdir
import os
from matplotlib import image
from matplotlib import pyplot as plt
import h5py
import cv2
from sklearn.model_selection import train_test_split


# for evaluation
from sklearn.metrics import classification_report
import itertools

# calculus
from pennylane import numpy as np

"""## ðŸ‘‰ Data Analysis

In this section we are going to introduce the used dataset and do some visualization in order to explore its contents

### About the dataset

The dataset has been downloaded from figshare website [link](https://figshare.com/articles/dataset/brain_tumor_dataset/1512427/5)

It is organized in matlab data format (.mat file). Each file stores a struct
containing the following fields for an image:

    - cjdata.label: 1 for meningioma, 2 for glioma, 3 for pituitary tumor
    - cjdata.PID: patient ID
    - cjdata.image: image data
    - cjdata.tumorBorder: a vector storing the coordinates of discrete points on tumor border.
            - For example, [x1, y1, x2, y2,...] in which x1, y1 are planar coordinates on tumor border.
            - It was generated by manually delineating the tumor border. So we can use it to generate
            - binary image of tumor mask.
    - cjdata.tumorMask: a binary image with 1s indicating tumor region

### Visualize the data

#### Labels
"""

# Counting labels
folder = "../brain_tumor_dataset/all/" # .mat files folder
directs = sorted(listdir(folder))
labels = []
for file in directs:
    f = h5py.File('../brain_tumor_dataset/all/'+file,'r')
    label = np.array(f.get("cjdata/label"))[0][0]
    labels.append(label)
labels = pd.Series(labels)
labels.shape

# Tumor types
names = ["meningioma", "glioma", "pituitary tumor"]
# Count labels
labelcounts = labels.value_counts().sort_index()
# change the index with th types
labelcounts.index = names

#print(labelcounts)

# create a barchart
ax = labelcounts.plot(
        kind='bar',
        figsize=(6, 6),
        width=0.5,
        color=['#5cb85c', '#d9534f', '#5bc0de'],
     )

# define the title
ax.set_title("Number of samples per Label", size=12)
# change font size for labells an legend
plt.xticks(fontsize=14, rotation=45)

# putting the numbers
i = 1
for p in ax.patches:
    width = p.get_width()
    height = p.get_height()
    x, y = p.get_xy()
    ax.annotate(str(i)+": "+str(height), (x + width/2, y + height*1.02), ha='center')
    i += 1

"""#### Pictures"""

folder = "../brain_tumor_dataset/all/" # .mat files folder
directs = sorted(listdir(folder))
labels = []
images = []
masks = []
for file in directs:
    f = h5py.File(folder+file,'r')
    label = np.array(f.get("cjdata/label"))[0][0]
    if label not in labels:
        #print(file)
        labels.append(label)
        img = np.stack((np.array(f.get("cjdata/image")),)*4, axis=-1)
        images.append(img)
        mask = np.array(f.get("cjdata/tumorMask"))
        masks.append(mask)
labels = np.asarray(labels)
images = np.asarray(images)
masks = np.asarray(masks)
labels.shape, images.shape, masks.shape

b = K.utils.to_categorical(masks, num_classes=4).astype(np.uint8)
tumor = np.zeros_like(images[:, :, :, 1:])
image_norm = cv2.normalize(images[:, :, :, 0], None, alpha=0, beta=255,
                      norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F).astype(np.uint8)

print(image_norm.shape)

# remove tumor part from image
tumor[:, :, :, 0] = image_norm * (b[:, :, :, 0])
tumor[:, :, :, 1] = image_norm * (b[:, :, :, 0])
tumor[:, :, :, 2] = image_norm * (b[:, :, :, 0])

# color tumor
tumor += b[:, :, :, 1:] * 255

tumor.shape

fig = plt.figure(figsize=(14, 10))
for i in range(3):
    fig.add_subplot(1, 3, i+1)
    plt.imshow(tumor[i], "gray")
    plt.title(names[int(labels[i]-1)])

plt.show()

"""## ðŸ‘‰ Model

In this section we will talk about our model and how we designed it

### Architecture

Based on classical Convolutional Neural Network Architecture (fig. 1) and pure Quantum Convolutional Neural Network (fig. 2) we came out with the Quantum Hybrid-Classical presented in the (fig. 3)

##### ðŸ‘‡ Fig. 1: Simple Convolutional Neural Network

<hr>

![CNN](CNN.png)

<br>

##### ðŸ‘‡ Fig. 2: Quantum Convolutional Neural Network

<hr>

![QCNN](QCNN1.png)

<br>

##### ðŸ‘‡ Fig. 3: Our Hybrid Quantum-Classical Convolutional Neural Network

<hr>

![Model](Model.jpg)


<br>

Resources

<hr>

[- CNN](https://www.researchgate.net/publication/331540139_A_State-of-the-Art_Survey_on_Deep_Learning_Theory_and_Architectures/figures?lo=1&utm_source=google&utm_medium=organic)
<br>
[- QCNN](https://arxiv.org/pdf/2009.09423.pdf)
<br>
[- Pennylane tutorial](https://pennylane.ai/qml/demos/tutorial_quanvolution.html?fbclid=IwAR3Sw-OvDokiY1bzltvyyLHnnlPvlVTnAiwH3HqjTYpLxnjSbibGBfaSmTA)

### First part: Features Extraction

<hr>
Defining Quantum Circuit and Quantum Convolutional function
"""

wires=4

dev4 = qml.device("default.qubit", wires=wires)  # define the simulator
@qml.qnode(dev4)
def CONVCircuit(phi, wires, i=0):
    """
    quantum convolution Node
    """
    # parameter
    theta = np.pi / 2

    qml.RX(phi[0] * np.pi, wires=0)
    qml.RX(phi[1] * np.pi, wires=1)
    qml.RX(phi[2] * np.pi, wires=2)
    qml.RX(phi[3] * np.pi, wires=3)

    qml.CRZ(theta, wires=[1, 0])
    qml.CRZ(theta, wires=[3, 2])
    qml.CRX(theta, wires=[1, 0])
    qml.CRX(theta, wires=[3, 2])
    qml.CRZ(theta, wires=[2, 0])
    qml.CRX(theta, wires=[2, 0])

    # Expectation value
    measurement = qml.expval(qml.PauliZ(wires=0))

    return measurement


def QCONV1(X, image_number, image_total, step=2):
    """
    quantum convolutional layer
    """

    #H, W, CH = X.shape
    H, W = X.shape
    step2 = 2
    out = np.zeros(((H//step), (W//step)))
    #progress = 0
    for i in range(0, W, step):
        #print("processing image "+str(image_number)+"/ "+str(image_total)+": "+str(int(((i/W+1))*100))+"% ", end="\r")
        print("processing image "+str(image_number)+"/ "+str(image_total)+": "+str(i)+"px   ", end="\r")
        for j in range(0, H, step):
            # get 2x2 pixels and make them 1D array
            phi = X[i:i+2, j:j+2].flatten()
            # Get Measurement
            measurement = CONVCircuit(phi, len(phi))
            out[i//step, j//step] = measurement

    return out

"""<hr>
Visualizing Quantum Circuit
"""

phi = [1, 1, 1, 1]
drawer = qml.draw(CONVCircuit)
print(drawer(phi, 4))

"""<hr>

Applying the Quantum Convolutional Layer
"""

# Images processing with a Quantum Convolutional Layer after being resized
folder = "../brain_tumor_dataset/all/" # .mat files folder
processFolder = "../brain_tumor_dataset/processed/allresized/"
start = timer()
w = 512
step = 2

k = 0
directs = sorted(listdir(folder))

for file in directs:
    all64 = sorted(listdir(processFolder))
    if file+".npz" in all64:
        continue
    f = h5py.File(folder+file, 'r')
    img = np.array(f.get("cjdata/image"))
    if img.shape[0] < 512:
        continue
    label = np.array(f.get("cjdata/label"))[0][0]

    scale_percent = 25 # percent of original size
    width = int(img.shape[1] * scale_percent / 100)
    height = int(img.shape[0] * scale_percent / 100)
    dim = (width, height)

    # resize image
    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)
    NorImages = resized/255

    processed = QCONV1(NorImages, str(k)+" "+file, (len(directs)-len(all64))/2, step)

    np.savez_compressed(processFolder+file, image=processed, label=label)
    k+=1
end = timer()
time = (end - start)
str(timedelta(seconds=round(time)))

"""<hr>
Visualization after applying quantum filter
"""

img = np.load("../brain_tumor_dataset/processed/allresized/1000.mat.npz")['image']
plt.imshow(img, "gray")
plt.show()

"""
### Second part: Classification

<hr>
Get processed images coupled with their labels"""

# get processed data
folder = "../brain_tumor_dataset/processed/allresized/"
directs = sorted(listdir(folder))


images = []
masks = []
labels = []
i = 0
for file in directs:
    try:
        data = np.load(folder+file)
        label = data["label"]
        img = np.stack((data["image"],), axis=-1)
        images.append(img)
        labels.append(label)
        i+=1
    except:
        continue

npimages = np.asarray(images)
nplabels = np.asarray(labels)

npimages.shape, nplabels.shape

"""<hr>

Splitting the data to 3 parts train/validation/test
"""

X_train, X_test, y_train, y_test = train_test_split(npimages, nplabels,
                                                    test_size=0.3,
                                                    random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test,
                                                    test_size=0.5,
                                                    random_state=42)

X_train.shape, X_test.shape, X_valid.shape, y_valid.shape, y_train.shape, y_test.shape

"""<hr>

Defining Fully Connected Layers with Tensorflow
"""

def Model():
    """
    Fully Connected Layer
    """
    model = K.models.Sequential([
        K.layers.Flatten(),
        K.layers.Dense(128, activation="relu"),
        K.layers.Dropout(0.5),
        K.layers.Dense(4, activation="softmax")
    ])

    model.compile(
        optimizer=tf.keras.optimizers.Adam(),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"],
    )
    return model

"""<hr>

Train the model
"""

### tf.random.set_seed(42)
q_model = Model()
checkpoint_path = "checkpoints/quantum.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

# Create a callback that saves the model's weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=0)

q_history = q_model.fit(
    X_train,
    y_train,
    validation_data=(X_valid, y_valid),
    batch_size=16,
    epochs=20,
    verbose=2,
    callbacks=[cp_callback]
)

q_model.save('QModel.h5')

"""<hr>

Plotting the results
"""

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))
ax1.plot(q_history.history["val_accuracy"], "-ob", label="val_accuracy")
ax1.plot(q_history.history["accuracy"], "-oc", label="accuracy")
ax1.set_ylim([0, 1])
ax1.set_title("Accuracy")
ax1.set_xlabel("Epoch")
ax1.legend()

ax2.plot(q_history.history["val_loss"], "-ob", label="val_loss")
ax2.plot(q_history.history["loss"], "-oc", label="loss")
ax2.set_title("Loss")
ax2.set_xlabel("Epoch")
ax2.legend()
plt.show()

"""## ðŸ‘‰ Evaluation
<hr>

Defining a method to plot the Confusion Matrix
"""

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    #print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

# Get Saved Model
q_model = K.models.load_model('QModel.h5')

"""<hr>
Get predicted labels
"""

yhat = q_model.predict(X_test)
yhat = yhat.argmax(axis=1)

yhat.shape, y_test.shape

"""<hr>

Printing the classification report using Sklearn
"""

print(classification_report(y_test, yhat))

"""<hr>

Computing & Plotting Confusion Matrix
"""

# Compute confusion matrix
cnf_matrix = tf.math.confusion_matrix(y_test, yhat)
np.set_printoptions(precision=2)
# Plot non-normalized confusion matrix
plt.figure(figsize=(6, 6))
plot_confusion_matrix(np.array(cnf_matrix[1:, 1:]), classes=['1 meningioma', '2 glioma', '3 pituitary tumor'], normalize=False,  title='Confusion matrix')

"""# ðŸ‘‰ Classical"""

# Images resizing
folder = "../brain_tumor_dataset/all/" # .mat files folder

w = 512
step = 8
k = 0
directs = sorted(listdir(folder))
images = []
labels = []

for file in directs:

    f = h5py.File(folder+file, 'r')
    img = np.array(f.get("cjdata/image"))
    if img.shape[0] < 512:
        continue

    label = np.array(f.get("cjdata/label"))[0][0]

    scale_percent = 25 # percent of original size
    width = int(img.shape[1] * scale_percent / 100)
    height = int(img.shape[0] * scale_percent / 100)
    dim = (width, height)

    # resize image
    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)

    images.append(np.stack((resized,), axis=-1))
    labels.append(label)
    print("image "+str(k)+"  ", end="\r")

    k+=1
images = np.asarray(images)/255
labels = np.asarray(labels)

images.shape

"""<hr>

Splitting the data to 3 parts train/validation/test
"""

X_train, X_test, y_train, y_test = train_test_split(images, labels,
                                                    test_size=0.3,
                                                    random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test,
                                                    test_size=0.5,
                                                    random_state=42)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""<hr>

Defining the DenseNet121 Model & Training it

[- Resource](https://www.tensorflow.org/api_docs/python/tf/keras/applications/densenet/DenseNet121)

"""

# create DenseNet121 Model
model = K.applications.DenseNet121(
    weights=None,
    input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]),
    classes=4,
)
# compile the model
model.compile(
        optimizer=K.optimizers.Adam(),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"],
)
checkpoint_path = "checkpoints/classical.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

# Create a callback that saves the model's weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=0)
# Training the model
history = model.fit(
    X_train,
    y_train,
    validation_data=(X_test, y_test),
    batch_size=16,
    epochs=20,
    verbose=1,
    callbacks=[cp_callback]
)

"""<hr>

Save the Model
"""

model.save('DenseNet121.h5')

"""<hr>

Plotting the results
"""

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))
ax1.plot(history.history["val_accuracy"], "-ob", label="val_accuracy")
ax1.plot(history.history["accuracy"], "-oc", label="accuracy")
ax1.set_ylim([0, 1])
ax1.set_title("Accuracy")
ax1.set_xlabel("Epoch")
ax1.legend()

ax2.plot(history.history["val_loss"], "-ob", label="val_loss")
ax2.plot(history.history["loss"], "-oc", label="loss")
ax2.set_title("Loss")
ax2.set_xlabel("Epoch")
ax2.legend()
plt.show()

"""## ðŸ‘‰ Evaluation
<hr>

Get Predicted labels
"""

# Get Saved Model
model = K.models.load_model('DenseNet121.h5')

yhat = model.predict(X_test)
yhat = yhat.argmax(axis=1)

"""<hr>

Printing the classification report using Sklearn
"""

print(classification_report(y_test, yhat))

"""<hr>

Computing & Plotting Confusion Matrix
"""

# Compute confusion matrix
cnf_matrix = tf.math.confusion_matrix(y_test, yhat)
np.set_printoptions(precision=2)

# Plot non-normalized confusion matrix
plt.figure(figsize=(6, 6))
plot_confusion_matrix(np.array(cnf_matrix[1:, 1:]), classes=['1 meningioma', '2 glioma', '3 pituitary tumor'], normalize=False,  title='Confusion matrix')

"""### Extra Ressources

- [Pennylane](https://pennylane.ai/)

- [Qiskit](https://qiskit.org/)

- [Quantum Computing Concepts â€“ Entanglement](https://www.youtube.com/watch?v=EjdIMBOWCWo)

- []()

### Versions
"""

!cat /etc/issue

!python --version

qml.__version__ # pennylane

tf.__version__

